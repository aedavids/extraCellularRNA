{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4be6a60",
   "metadata": {},
   "source": [
    "# Generated TCGA Matrix Creation Scripts\n",
    "```\n",
    "Andrew Davidson\n",
    "aedavids@ucsc.edu\n",
    "4/27/22\n",
    "```\n",
    "ref: extraCellularRNA/terra/jupyterNotebooks/createFailedSampleDataSet-TCGA.{ipynb,html}\n",
    "\n",
    "The salmonTarQuantWorkflow.wdl was run for each of the Terra TCGA workspaces. The next part of our reasearch requires all the salmon counts be gathered into a single matrix. We are unable to do this using Terra. Our work around is to copy the quant files to a GCP native project and use apache spark to create the matricies. \n",
    "\n",
    "This notebook creates\n",
    "1. the gsutil scripts requried to transfer the terra workspace files to the GCP native project. The natve project can not access the workspace file, directly. how ever gsutil is able to copy\n",
    "2. The corresponding colData.csv files for each workspace. This is the meta data need for future processing\n",
    "\n",
    "createFailedSampleDataSet-TCGA.{ipynb,html} demonstrates how to identifyed the samples we want to construct or matricies from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d6e05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on 2022-04-29 16:37:08\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "today = now.strftime('%Y-%m-%d')\n",
    "currentTime = now.strftime('%H:%M:%S')\n",
    "print(\"run on {}\".format( today +  \" \" + currentTime ))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c5379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the bucket in the native gcp project we need to copy the files to \n",
    "DESTINATION_BUCKET_ID = \"anvil-tcga-edu-ucsc-kiim-lab-spark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306917bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# back ups of terra data models are stored in a separate repo\n",
    "# so that branch merges do not loose data model version\n",
    "rootDir = \"../../../terraDataModels/test-aedavids-proj/TCGA\"\n",
    "listOfWorkSpacePath = rootDir + \"/\" + \"listOfWorkSpaces.csv\" \n",
    "workspaceDF = pd.read_csv( listOfWorkSpacePath )\n",
    "workSpaceNamesList = workspaceDF.loc[:, \"wokspace\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc5485",
   "metadata": {},
   "source": [
    "# Find column with results generated by salmonTarQuantWorkflow v 4\n",
    "This workflow uses the salmon paired read bug fix. The reson the name is not always the the same is that there are 33 different workspaces. I had to name the output col manual for each run. For unknow reason Terra would not let define these values in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6442f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataModel( rootDir, workspaceName, entityName ) :\n",
    "    '''\n",
    "    entity referers to one of the terra data model tsv files. for exzmple 'sample'\n",
    "    '''\n",
    "    dataModelTSV = rootDir + \"/\" + workspaceName + \"/\" + entityName + \".tsv\"\n",
    "    dataModelDF = pd.read_csv(dataModelTSV, delimiter='\\t')\n",
    "    return dataModelDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02df81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findQuantFileColumnName(workSpaceNamesList, skipWorkspaceList) :\n",
    "    '''\n",
    "    loads most of the tcga sample tsv files. See code for workspaces that are where skipped.\n",
    "    they where skipped because we not all the expected samples ran.\n",
    "    \n",
    "    returns a dictionary.\n",
    "        key is the workspaceName\n",
    "        value is (quantColName, df)\n",
    "    '''\n",
    "    dataDict = dict()\n",
    "\n",
    "\n",
    "    for workspaceName in workSpaceNamesList:\n",
    "        if workspaceName in skipWorkspaceList:\n",
    "            continue\n",
    "\n",
    "        #print(workspaceName)\n",
    "        df = readDataModel( rootDir, workspaceName, entityName = \"sample\" )\n",
    "        quantMatchlist = [s for s in df.columns if \"quantF\" in s]\n",
    "        colName = [s for s in quantMatchlist if \"3\" in s][0]\n",
    "        #print(colName)\n",
    "        #print()\n",
    "        dataDict[workspaceName] = (colName, df) \n",
    "        \n",
    "    return dataDict\n",
    "        \n",
    "# we need to dig into these workspaces to figure out. why run failed\n",
    "# check out the minimap and star wdls for a good example of how to \n",
    "# works with single end, paired end and multple replicants fastq files\n",
    "# there is s a good chance that is the source of our bugs\n",
    "skipWorkspaceList = ['TCGA_DLBC_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab'\n",
    "               ,'TCGA_GBM_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab'\n",
    "               ,'TCGA_LAML_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab'\n",
    "               ,'TCGA_SARC_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab'\n",
    "              ]\n",
    "dataDict = findQuantFileColumnName(workSpaceNamesList, skipWorkspaceList)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c4c15c",
   "metadata": {},
   "source": [
    "## Find samples with quant files. and sample that failed and need to re-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e1b2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSamplesWithMissingQuantFile(rootDir, workspaceName, quantFileColName):\n",
    "    '''\n",
    "    returns a data frame of failed samples\n",
    "    '''\n",
    "    sampleDF = readDataModel( rootDir, workspaceName, entityName = \"sample\" )     \n",
    "    print(\"\\nworkspace: {}\".format(workspaceName))\n",
    "    \n",
    "    mRNARowsLogicalPS = sampleDF['mRNASeq_fastq_path'].notna()\n",
    "    nunMRNAFiles = sum( mRNARowsLogicalPS )\n",
    "    print(\"number of mRNASeq_fastq_path files: {}\".format(nunMRNAFiles))\n",
    "    mRNA_DF = sampleDF.loc[mRNARowsLogicalPS,:]\n",
    "\n",
    "    # find rows that have fastq files but are missing results. ie 'quantFilePaired' value\n",
    "    passedSamplesLogicalPS = mRNA_DF[quantFileColName].notna()\n",
    "    numPassed = sum(passedSamplesLogicalPS) \n",
    "    \n",
    "    passedSamplesDF = mRNA_DF.loc[passedSamplesLogicalPS,:]\n",
    "    \n",
    "    failedSampleLogicalPS =  mRNA_DF[quantFileColName].isna()\n",
    "    failedSampleDF = mRNA_DF.loc[failedSampleLogicalPS,:]\n",
    "    \n",
    "    numFailed = nunMRNAFiles - numPassed\n",
    "   \n",
    "    print(\"num passed:{}\".format(numPassed))\n",
    "    print(\"num failed:{}\".format(numFailed))\n",
    "    \n",
    "    return failedSampleDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c383021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSamplesWithQuantFile(sampleDF, quantFileColName):   \n",
    "    '''\n",
    "    returns a data frame with all these samples that have quant files\n",
    "    '''\n",
    "    mRNARowsLogicalPS = sampleDF['mRNASeq_fastq_path'].notna()\n",
    "    nunMRNAFiles = sum( mRNARowsLogicalPS )\n",
    "    print(\"number of mRNASeq_fastq_path files: {}\".format(nunMRNAFiles))\n",
    "    mRNA_DF = sampleDF.loc[mRNARowsLogicalPS,:]\n",
    "\n",
    "    # find rows that have fastq files but are missing results. ie 'quantFilePaired' value\n",
    "    passedSamplesLogicalPS = mRNA_DF[quantFileColName].notna()\n",
    "    numPassed = sum(passedSamplesLogicalPS) \n",
    "    \n",
    "    passedSamplesDF = mRNA_DF.loc[passedSamplesLogicalPS,:]\n",
    "    \n",
    "    failedSampleLogicalPS =  mRNA_DF[quantFileColName].isna()\n",
    "    failedSampleDF = mRNA_DF.loc[failedSampleLogicalPS,:]\n",
    "    \n",
    "    numFailed = nunMRNAFiles - numPassed\n",
    "   \n",
    "    print(\"num passed:{}\".format(numPassed))\n",
    "    print(\"num failed:{}\".format(numFailed))\n",
    "    \n",
    "    return passedSamplesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c5c9724",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceName: TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab quantColName: quantFile3\n",
      "number of mRNASeq_fastq_path files: 177\n",
      "num passed:105\n",
      "num failed:72\n",
      "quantDF.shape:(105, 63)\n",
      "debugDF.head():\n",
      "   entity:sample_id   participant  \\\n",
      "1   READ-AF-2687-TP  READ-AF-2687   \n",
      "3   READ-AF-2689-NT  READ-AF-2689   \n",
      "6   READ-AF-2690-TP  READ-AF-2690   \n",
      "8   READ-AF-2691-NT  READ-AF-2691   \n",
      "11  READ-AF-2692-NT  READ-AF-2692   \n",
      "\n",
      "                                                                                                                                                                                     quantFile3  \n",
      "1   gs://fc-secure-8a69fc00-b6c9-4179-aee5-f1e47a4475dd/34b2bbfb-4f9a-41d4-bfd8-b55a8e1987de/quantify/ef52a514-2fc0-4e85-946a-2bbbbc56ab96/call-salmon_paired_reads/READ-AF-2687-TP.quant.sf.gz  \n",
      "3   gs://fc-secure-8a69fc00-b6c9-4179-aee5-f1e47a4475dd/34b2bbfb-4f9a-41d4-bfd8-b55a8e1987de/quantify/5b5b1621-f465-482b-a098-3c34a83ebda3/call-salmon_paired_reads/READ-AF-2689-NT.quant.sf.gz  \n",
      "6   gs://fc-secure-8a69fc00-b6c9-4179-aee5-f1e47a4475dd/34b2bbfb-4f9a-41d4-bfd8-b55a8e1987de/quantify/fb5d3684-890a-4529-a003-392eda7c81eb/call-salmon_paired_reads/READ-AF-2690-TP.quant.sf.gz  \n",
      "8   gs://fc-secure-8a69fc00-b6c9-4179-aee5-f1e47a4475dd/34b2bbfb-4f9a-41d4-bfd8-b55a8e1987de/quantify/48829ed4-e7d3-42d8-b876-56f6884e4e61/call-salmon_paired_reads/READ-AF-2691-NT.quant.sf.gz  \n",
      "11  gs://fc-secure-8a69fc00-b6c9-4179-aee5-f1e47a4475dd/34b2bbfb-4f9a-41d4-bfd8-b55a8e1987de/quantify/0223346b-95f8-4bc6-9d0e-7522f8e9f30c/call-salmon_paired_reads/READ-AF-2692-NT.quant.sf.gz  \n"
     ]
    }
   ],
   "source": [
    "# test data set\n",
    "#\n",
    "# workspace: TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab\n",
    "# number of mRNASeq_fastq_path files: 177\n",
    "# num passed:105\n",
    "# num failed:72\n",
    "# failedSampleDF.shape:(72, 63)\n",
    "# quantFile3\n",
    "\n",
    "def testfindSamplesWithQuantFiles():\n",
    "    workspaceName = \"TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab\"\n",
    "    quantColName, sampleDF = dataDict[workspaceName]\n",
    "    print(\"workspaceName: {} quantColName: {}\".format(workspaceName, quantColName))\n",
    "\n",
    "    quantDF = findSamplesWithQuantFile(sampleDF, quantColName)\n",
    "    print(\"quantDF.shape:{}\".format(quantDF.shape))\n",
    "    numQuantFiles = quantDF.shape[0]\n",
    "    assert (numQuantFiles == 105), \"ERROR expected 105 quant files in \" + workspaceName\n",
    "    \n",
    "#     print(\"quantDF.head():\\n{}\".format(quantDF.head()))\n",
    "    \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    debugCols = ['entity:sample_id', 'participant', quantColName]\n",
    "    debugDF = quantDF.loc[:, debugCols]\n",
    "    print(\"debugDF.head():\\n{}\".format(debugDF.head()) )\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.max_colwidth')\n",
    "    \n",
    "testfindSamplesWithQuantFiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e7c3f5",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Create col data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4063a385",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceName: TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab quantColName: quantFile3\n",
      "number of mRNASeq_fastq_path files: 177\n",
      "num passed:105\n",
      "num failed:72\n",
      "quantDF.shape:(105, 63)\n",
      "colDataDF.shape:(105, 7)\n",
      "entity:sample_id\n",
      "entity:participant_id\n",
      "tcga_sample_id\n",
      "Cohort\n",
      "Age\n",
      "Gender\n",
      "sample_type\n",
      "\n",
      "  entity:sample_id entity:participant_id   tcga_sample_id Cohort  Age  Gender  \\\n",
      "0  READ-AF-2687-TP          READ-AF-2687  TCGA-AF-2687-01   READ   57    male   \n",
      "1  READ-AF-2689-NT          READ-AF-2689  TCGA-AF-2689-11   READ   41  female   \n",
      "2  READ-AF-2690-TP          READ-AF-2690  TCGA-AF-2690-01   READ   76  female   \n",
      "3  READ-AF-2691-NT          READ-AF-2691  TCGA-AF-2691-11   READ   48  female   \n",
      "4  READ-AF-2692-NT          READ-AF-2692  TCGA-AF-2692-11   READ   54  female   \n",
      "\n",
      "  sample_type  \n",
      "0          TP  \n",
      "1          NT  \n",
      "2          TP  \n",
      "3          NT  \n",
      "4          NT  \n"
     ]
    }
   ],
   "source": [
    "def createColDataDataFrame(rootDir, workspaceName, quantDF):\n",
    "    \n",
    "    participantDF = readDataModel( rootDir, workspaceName, entityName = \"participant\")\n",
    "    \n",
    "    \n",
    "#     some patients have multiple samples    \n",
    "#     quantParticipantSeries = quantDF[\"participant\"]\n",
    "    \n",
    "#     print(\"num Unique quantParticipantSeries.shape :{}\".format(quantParticipantSeries.unique().shape) )\n",
    "#     participantSeries = participantDF[\"entity:participant_id\"]\n",
    "    \n",
    "#     selectRows =  participantSeries.isin( quantParticipantSeries )\n",
    "#     colDataDF = participantDF.loc[selectRows, :]\n",
    "    \n",
    "    \n",
    "    # merge implements inner join. ie sql 'select where'\n",
    "    retDF = pd.merge(participantDF, quantDF, \n",
    "                     left_on = \"entity:participant_id\",\n",
    "                     right_on = \"participant\" )\n",
    "    \n",
    "#     for c in retDF.columns:\n",
    "#         print(c)\n",
    "    \n",
    "    # ??? not tissue id or site id ???\n",
    "    retCols = ['entity:sample_id'\n",
    "               ,'entity:participant_id'\n",
    "               , 'tcga_sample_id'\n",
    "               , 'Cohort'\n",
    "               , 'Age'\n",
    "               , 'Gender'\n",
    "               , 'sample_type'\n",
    "              ]\n",
    "    \n",
    "    return retDF.loc[:, retCols].sort_values(by=\"entity:sample_id\", ascending=True)\n",
    "    \n",
    "def testCreateColDataDataFrame():\n",
    "    workspaceName = \"TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab\"\n",
    "    quantColName, sampleDF = dataDict[workspaceName]\n",
    "    print(\"workspaceName: {} quantColName: {}\".format(workspaceName, quantColName))\n",
    "\n",
    "    quantDF = findSamplesWithQuantFile(sampleDF, quantColName)\n",
    "    print(\"quantDF.shape:{}\".format(quantDF.shape))    \n",
    "\n",
    "    colDataDF = createColDataDataFrame(rootDir, workspaceName, quantDF)\n",
    "    print(\"colDataDF.shape:{}\".format(colDataDF.shape)) \n",
    "    for c in colDataDF.columns:\n",
    "        print(c)\n",
    "\n",
    "    print()\n",
    "    print(colDataDF.head())\n",
    "    \n",
    "testCreateColDataDataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e06f3f6",
   "metadata": {},
   "source": [
    "## Create script to copy quant files from terra to native gcp project bucket\n",
    "We can run spark n the native project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7fcec3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceName: TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab quantColName: quantFile3\n",
      "number of mRNASeq_fastq_path files: 177\n",
      "num passed:105\n",
      "num failed:72\n",
      "quantDF.shape:(105, 63)\n",
      "first copy comand\n",
      "gsutil -m cp gs://fc-secure-8a69fc00-b6c9-4179-aee5-f1e47a4475dd/34b2bbfb-4f9a-41d4-bfd8-b55a8e1987de/quantify/ef52a514-2fc0-4e85-946a-2bbbbc56ab96/call-salmon_paired_reads/READ-AF-2687-TP.quant.sf.gz gs://anvil-tcga-edu-ucsc-kiim-lab-spark/TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab/\n",
      "\n",
      " second copy command\n",
      "gsutil -m cp gs://fc-secure-8a69fc00-b6c9-4179-aee5-f1e47a4475dd/34b2bbfb-4f9a-41d4-bfd8-b55a8e1987de/quantify/5b5b1621-f465-482b-a098-3c34a83ebda3/call-salmon_paired_reads/READ-AF-2689-NT.quant.sf.gz gs://anvil-tcga-edu-ucsc-kiim-lab-spark/TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab/\n"
     ]
    }
   ],
   "source": [
    "def createCopyCommand( quantFilesSeries, workspaceName, dstBucketId):\n",
    "    numQuantfiles = quantFilesSeries.shape[0]\n",
    "    retList = [\"\"] * numQuantfiles\n",
    "    for i in range(numQuantfiles):\n",
    "        file = quantFilesSeries.iloc[i]\n",
    "        retList[i] = \"gsutil -m cp {} gs://{}/{}/\".format(file, dstBucketId, workspaceName)\n",
    "        \n",
    "    return retList\n",
    "    \n",
    "def testCreateCopyCommand():\n",
    "    workspaceName = \"TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab\"\n",
    "    quantColName, sampleDF = dataDict[workspaceName]\n",
    "    print(\"workspaceName: {} quantColName: {}\".format(workspaceName, quantColName))\n",
    "\n",
    "    quantDF = findSamplesWithQuantFile(sampleDF, quantColName)\n",
    "    print(\"quantDF.shape:{}\".format(quantDF.shape))\n",
    "    numQuantFiles = quantDF.shape[0]\n",
    "    assert (numQuantFiles == 105), \"ERROR expected 105 quant files in \" + workspaceName\n",
    "    \n",
    "    quantFiles = quantDF.loc[:,quantColName]\n",
    "    shellScriptList = createCopyCommand( quantFiles, workspaceName, DESTINATION_BUCKET_ID)\n",
    "    print(\"first copy comand\")\n",
    "    print(shellScriptList[0])\n",
    "    print(\"\\n second copy command\")\n",
    "    print(shellScriptList[1])\n",
    "    \n",
    "    assert len(shellScriptList) == numQuantFiles, \"ERROR expected {} copy commands\".format(numQuantFiles)\n",
    "    \n",
    "testCreateCopyCommand()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4c2ab",
   "metadata": {},
   "source": [
    "# Create matrix scripts and col data for all workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3d54b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceName: TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab quantColName: quantFile3\n",
      "number of mRNASeq_fastq_path files: 177\n",
      "num passed:105\n",
      "num failed:72\n",
      "quantDF.shape:(105, 63)\n",
      "colDataDF.shape:(105, 7)\n",
      "create dir: ../../../terraDataModels/test-aedavids-proj/TCGA/TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab/generateTCGAMatrixCreationScripts.ipynb.out\n",
      "wrote file: ../../../terraDataModels/test-aedavids-proj/TCGA/TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab/generateTCGAMatrixCreationScripts.ipynb.out/TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab_colData.csv\n",
      "wrote file: ../../../terraDataModels/test-aedavids-proj/TCGA/TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab/generateTCGAMatrixCreationScripts.ipynb.out/TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab_copyFromTerraToNativeGCP.sh\n"
     ]
    }
   ],
   "source": [
    "def run(rootDir, dstBucketId, workspaceName, quantColName, sampleDF):\n",
    "    '''\n",
    "    finds quant.sf files, creates colData.csv file, and script to copy quant files\n",
    "    from terra to gcp bucket we and read using apache spark\n",
    "    '''\n",
    "    \n",
    "    quantDF = findSamplesWithQuantFile(sampleDF, quantColName)\n",
    "    print(\"quantDF.shape:{}\".format(quantDF.shape))    \n",
    "\n",
    "    colDataDF = createColDataDataFrame(rootDir, workspaceName, quantDF)\n",
    "    print(\"colDataDF.shape:{}\".format(colDataDF.shape)) \n",
    "\n",
    "    quantFiles = quantDF.loc[:,quantColName]\n",
    "    shellScriptList = createCopyCommand( quantFiles, workspaceName, dstBucketId)\n",
    "\n",
    "    # save \n",
    "    outDirPath = Path(rootDir + \"/\" + workspaceName + \"/\" +  \"generateTCGAMatrixCreationScripts.ipynb.out\")\n",
    "    print(\"create dir: {}\".format(outDirPath))\n",
    "    outDirPath.mkdir( parents=True, exist_ok=True )\n",
    "    \n",
    "    colDataFilePath = outDirPath.joinpath(workspaceName + \"_colData.csv\")\n",
    "    colDataDF.to_csv(colDataFilePath, index=False)\n",
    "    print(\"wrote file: {}\".format(colDataFilePath))\n",
    "    \n",
    "    scriptpPath = outDirPath.joinpath(workspaceName + \"_copyFromTerraToNativeGCP.sh\")\n",
    "    with open(scriptpPath, 'w') as fp:\n",
    "        for cmd in shellScriptList:\n",
    "            fp.write(\"{}\\n\".format(cmd))   \n",
    "        \n",
    "    print(\"wrote file: {}\".format(scriptpPath))\n",
    "\n",
    "    \n",
    "\n",
    "def testRun():\n",
    "    workspaceName = \"TCGA_READ_ControlledAccess_V1-0_DATA_edu_ucsc_kim_lab\"\n",
    "    quantColName, sampleDF = dataDict[workspaceName]\n",
    "    print(\"workspaceName: {} quantColName: {}\".format(workspaceName, quantColName))    \n",
    "    run(rootDir, DESTINATION_BUCKET_ID, workspaceName, quantColName, sampleDF)\n",
    "    \n",
    "testRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe042d08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aedwip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-be6ef583f72e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maedwip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrunAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipWorkspaceList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdstBucketId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mworkspaceName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aedwip' is not defined"
     ]
    }
   ],
   "source": [
    "aedwip\n",
    "\n",
    "def runAll(dataDict, skipWorkspaceList, dstBucketId):\n",
    "    for workspaceName,t in dataDict.items():\n",
    "        colName, df = t\n",
    "        \n",
    "        if workspaceName in skipWorkspaceList:\n",
    "            print(\"\\n***** skipping: {}\".format(workspaceName))\n",
    "            continue\n",
    "                \n",
    "        quantColName, sampleDF = dataDict[workspaceName]\n",
    "        print(\"\\n*******\\nworkspaceName: {} quantColName: {}\".format(workspaceName, quantColName))\n",
    "        \n",
    "        run(rootDir, dstBucketId, quantColName, sampleDF)\n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "                \n",
    "run( rootDir, dataDict, skipWorkspaceList, DESTINATION_BUCKET_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
