#
# enrichSignatureGeneConfig.py
#
# Andrew E. Davidson
# aedavids@ucsc.edu
#
# EnrichSignatureGeneConfigCLI CommandLine display the doc string 
'''
1) calls BestRemoveHighDegreeSignatureGeneConfig::findGenes().
2) finds class/categories/types that do not have any unique genes.
3) add the next best gene.
'''

import logging
import os
import pandas as pd
import pprint as pp

from analysis.bestRemoveHighDegreeSignatureGeneConfig import BestRemoveHighDegreeSignatureGeneConfig
from analysis.enrichSignatureGeneConfigCLI import EnrichSignatureGeneConfigCLI
from analysis.utilities import  findAllGenes
from analysis.utilities import findElementsInIntersectionsWithDegree
from analysis.utilities import fileNameToDictKey
from analysis.utilities import findSetsWithDegree
from analysis.utilities import findIntersectionsWithDegree

# global variables use by PipelineCommandLine
__all__ = []
__version__ = 0.1
__author__ = "Andrew Davidson aedavids@ucsc.edu"
__date__ = '2023-12-14'
__updated__ = '2023-12-14'

################################################################################
class EnrichSignatureGeneConfig( BestRemoveHighDegreeSignatureGeneConfig  ):
    '''
    TODO

    try to insure each type has a degree1 intersection with a minium of number of genes
    '''

    logger = logging.getLogger(__name__)

    ################################################################################
    def __init__(self, 
                    dataSetName : str, 
                    design : str, 
                    padjThreshold : float, 
                    lfcThreshold : float, 
                    n : int, 
                    localCacheRootPath : str, 
                    title : str,
                    intersectionDictionaryPath : str,
                    degreeThreshold : int,
                    numberOfGenesToAdd : int) :
        super().__init__(
                    dataSetName=dataSetName,
                    design=design,
                    padjThreshold=padjThreshold,
                    lfcThreshold=lfcThreshold,
                    n=n,
                    localCacheRootPath=localCacheRootPath,
                    title=title,
                    intersectionDictionaryPath=intersectionDictionaryPath,
                    degreeThreshold=degreeThreshold
        )
        '''
        TODO

        arguments:
            numberOfGenesToAdd: 
                TODO AEDWIP bad name. Ensure each degree1 intersection has at least numberOfGenesToAdd elements
        
            intersectionDictionaryPath : str
                output from upstream stage of pipeilne. A dictionary key is multi-index identifying sets 
                that share elements. Value is the list of shared elements. 

                format example: ./analysis/test/data/intersection.dict

                see plots.test.testUpsetPlots testIntersection()
        '''

        # The super() implements the upstream portion of our pipeline
        # we started by selecting the best "n" genes
        # we should start looking for additional genes at index n + 1
        self.startSearchIdx = n

        # keep track of all genes we add accross all fileName
        # key: fileName, value = deseq results for gene
        # use dictionary to make it easy to create log entry
        self.addGenesDict = dict()

        # fast way to test candidate genes for uniqueness
        self.addGenesSet = set()

        # self.interesectionDict is a super data member
        self.degree1IntersectionDict = findIntersectionsWithDegree(self.intersectionDict, degree=1)

        # intersectionDict is typically generated by upset plot
        # part of a our pipeline. This is from a previous pipeline run.
        # The plot run after signature gene selection
        self.degree1Sets = findSetsWithDegree(self.intersectionDict, 1)

        # find upstream genes from sets with degree1
        # These are the smallest set of genes we might return
        self.upstreamDegree1GeneSet = findElementsInIntersectionsWithDegree(self.intersectionDict, 1)

        self.globalGenes = findAllGenes(self.intersectionDict)


        # self.allCategoriesSet = findAllCategories(self.intersectionDict)

        # self.categoriesToEnrich = self.allCategoriesSet - self.degree1Sets 

        self.numberOfGenesToAdd = numberOfGenesToAdd

    ################################################################################
    def findGenes(self, deseqDF : pd.DataFrame, fileName : str ) -> pd.DataFrame :
        '''
        1) calls BestRemoveHighDegreeSignatureGeneConfig::findGenes()
        2) finds class/categories/types that do not have any unique genes
        3) add the next best genes

        Note: if we could sort the class that do not have unique genes by sensitivity,
        the weaks classes would get high rank genes

        arguments
            deseqDF :
                todo

            fileName:
                key for addGenesDict
 
        ref: analysis.test.testEnrichSignatureGeneConfig

        '''
        self.logger.info("BEGIN")

        # sortedDF all genes with lcf2 > threshold and padj < threshold, sorted by base mean
        sortedDF = self._select(deseqDF, fileName)

        # we want to be able to use iloc to iterate over the rows
        # copy the sorted index to a new column named rank
        # assign a new index from 0 ... num rows -1
        sortedDF = sortedDF.reset_index(names="rank")

        # bestDF = best n, remove poor discriminators
        # poor discriminators are genes that are shared between may categories
        bestNDF= super().findGenes(deseqDF, fileName)

        genesToAddDF = pd.DataFrame()
        category = fileName.removesuffix( "_vs_all.results" )
        key = fileNameToDictKey(fileName)

        localAddGenes = []
        uniqueGenes = []
        if category in self.degree1Sets:
            # the keys of the intersection dictionary are tuples
            # degree1 keys are of form ('Vagina',) weird
            uniqueGenes = self.degree1IntersectionDict[key]

        self.logger.info(f'BEGIN category: {category} uniqueGenes : {uniqueGenes}')
        #self.logger.debug(f'AEDWIP is FAM107A in uniqueGenes? : {"FAM107A" in uniqueGenes}')


        if len(uniqueGenes) < self.numberOfGenesToAdd:
            n = len(uniqueGenes)
            self.logger.debug(f'category: {category} init n : {n}')

            # search over the remaining rows
            self.logger.info(f'range({self.startSearchIdx, sortedDF.shape[0]})')
            for i in range(self.startSearchIdx, sortedDF.shape[0]):
                if n >= self.numberOfGenesToAdd:
                    break

                candidateRowSeries = sortedDF.iloc[i, :]
                candidateName = candidateRowSeries.loc["name"]

                if candidateName not in self.addGenesSet:
                    # if candidateName not in self.upstreamDegree1GeneSet: aedwip this should be all. Not going to work, we reduced
                    if candidateName not in self.globalGenes: 
                        # we found a unique gene
                        # add to list of global additions
                        self.addGenesSet.add( candidateName )

                        # add to list of local addition
                        localAddGenes.append( candidateName )

                        n = n + 1
                        self.logger.debug(f'category: {category}  n : {n} added : {candidateName}')

            self.logger.info(f'category : {category} completed search. i : {i} len(localAddGenes) : {len(localAddGenes)}')

        if len(localAddGenes) > 0:
            # make down stream analysis easier
            # log ranks of additions. In future we might want to do something 
            # more clever with ranking. provide evidence for go/no go
            selectRowsWithRank = sortedDF.loc[:, "name"].isin(localAddGenes)
            rankedAdditionDF = sortedDF.loc[selectRowsWithRank, : ].sort_values(by="baseMean", ascending=False)
            self.logger.info(f'category : {category} ranked additions \n {pp.pformat(rankedAdditionDF)}')

            # use deseqDF, sortedDF has an extra column.
            # concat will not work with extra column
            selectRows = deseqDF.loc[:, "name"].isin(localAddGenes)
            # sort to make down stream analysis easier. Matches bestN
            uniqueGenesDF = deseqDF.loc[selectRows, : ].sort_values(by="baseMean", ascending=False)

            self.logger.debug(f'category : {category} add \n{pp.pformat(uniqueGenesDF)}')
            retDF = pd.concat( [bestNDF, uniqueGenesDF])
        else:
            self.logger.info(f'category : {category} was not enriched len(uniqueGenes): {len(uniqueGenes)} >= self.numberOfGenesToAdd :{self.numberOfGenesToAdd}')
            retDF = bestNDF

        self.logger.info("END")
        return retDF

    ################################################################################
    def __del__(self):
        '''
        __del__ like a C++ destructor
        '''
        self.logger.info(f'number of genes that will be added to signature matrix: {len(self.addGenesSet)}')
        self.logger.info(f'genes that will be added to signature matrix\n{self.addGenesSet}')
        self.logger.info(f'addGenesDict: \n{pp.pformat(self.addGenesDict, indent=4, sort_dicts=True)}')


################################################################################
def main(inCommandLineArgsList=None):
    '''
    use to test parsing of vargs
    '''
    # we only configure logging in main module
    loglevel = "WARN"
    loglevel = "INFO"
    # logFMT = "%(asctime)s %(levelname)s [thr:%(threadName)s %(name)s %(funcName)s() line:%(lineno)s] [%(message)s]"
    logFMT = "%(asctime)s %(levelname)s %(name)s %(funcName)s() line:%(lineno)s] [%(message)s]"
    logging.basicConfig(format=logFMT, level=loglevel)    

    logger = logging.getLogger(os.path.basename(__file__))
    logger.warning("BEGIN")

    #
    # always log run time env to make debug easier
    #
    ORIG_PYTHONPATH = os.environ['PYTHONPATH']
    logger.warning(f'PYTHONPATH : {ORIG_PYTHONPATH}')
    logger.warning(f'FILE: {__file__}')
    logger.warning(f'PWD: {os.getcwd()}')

    cli = EnrichSignatureGeneConfigCLI(version=__version__ , 
                            author=__author__ ,
                            date=__date__, 
                            update=__updated__)
    
    if inCommandLineArgsList is None:
        cli.parse()
    else:
        cli.parse( inCommandLineArgsList )

    logger.warning(f'command line arguments : {cli.args}')

    design          = cli.args.design 
    padjThreshold   = cli.args.padjThreshold
    lfcThreshold    = cli.args.lfcThreshold
    dataSetName     = cli.args.dataSetName
    number          = cli.args.number
    title           = cli.args.title
    localCacheRoot  = cli.args.localCacheRoot
    intersectionDictPath = cli.args.intersectionDict
    degreeThreshold = cli.args.degreeThreshold
    numUnique       = cli.args.numUnique

    logger.warning(f'END')

################################################################################
if __name__ == '__main__':
    '''
    hack used to test parsing of vargs
    '''
    main( inCommandLineArgsList=["--design", "tilda_gender_category",
                                 "--padjThreshold", "0.001",
                                 "--lfcThreshold", "2.0",
                                 "--dataSetName", "GTEx_TCGA",
                                 "--number" , "10",
                                 "--title", "a vs all",
                                 "--localCacheRoot", "myCacheRoot",
                                 "--intersectionDict", "./analysis/test/data/intersection.dict",
                                 "--degreeThreshold", "5",
                                # "--numUnique", "3"
                                ])



